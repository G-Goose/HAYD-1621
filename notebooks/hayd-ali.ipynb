{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 00:56:10.054002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-10 00:56:10.337873: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-10 00:56:10.370326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-10 00:56:10.370361: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-10 00:56:10.415378: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-10 00:56:11.048612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-10 00:56:11.048683: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-10 00:56:11.048688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.applications import EfficientNetB0, InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.math import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n",
      "Using 5741 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 01:10:00.222216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-05-10 01:10:00.223144: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-10 01:10:00.223385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hp-ali): /proc/driver/nvidia/version does not exist\n",
      "2024-05-10 01:10:00.228416: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = image_dataset_from_directory(\n",
    "    directory='../raw_data/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(299, 299),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='both',\n",
    "    # verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = image_dataset_from_directory(\n",
    "    directory='../raw_data/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(299, 299),\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    # verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.10.0\n",
      "tensorflow-estimator==2.10.0\n",
      "tensorflow-io-gcs-filesystem==0.37.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([299, 299, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=train_ds.element_spec[0].shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 7), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 299, 299, 3)\n",
      "(32, 7)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in val_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(class_names[labels[i]])\n",
    "#     plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(img, label):\n",
    "    return preprocess_input(img), label\n",
    "\n",
    "preproc_test_ds = test_ds.map(preprocess_data)\n",
    "preproc_train_ds = train_ds.map(preprocess_data)\n",
    "preproc_val_ds = val_ds.map(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "# base_model.trainable = False\n",
    "\n",
    "# aug1 = layers.RandomFlip(\"horizontal\")\n",
    "# aug2 = layers.RandomRotation(0.1)\n",
    "# # aug3 = layers.RandomZoom(0.1)\n",
    "\n",
    "# flatten_layer = Flatten()\n",
    "\n",
    "# dense_layer1 = Dense(700, activation='relu')\n",
    "# dropout1 = Dropout(0.25)\n",
    "# # dense_layer2 = Dense(250, activation='relu')\n",
    "# # dropout2 = Dropout(0.1)\n",
    "# dense_layer3 = Dense(70, activation='relu')\n",
    "# # dropout3 = Dropout(0.1)\n",
    "\n",
    "# prediction_layer = Dense(7, activation='softmax')\n",
    "\n",
    "\n",
    "# model = Sequential([\n",
    "#     base_model,\n",
    "#     aug1,\n",
    "#     aug2,\n",
    "# #     aug3,\n",
    "#     flatten_layer,\n",
    "#     dense_layer1,\n",
    "#     dropout1,\n",
    "#     dense_layer2,\n",
    "#     dropout2,\n",
    "#     dense_layer3,\n",
    "# #     dropout3,\n",
    "#     prediction_layer\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = train_ds.element_spec[0].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 46s 1us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=(img_shape))\n",
    "x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "x = layers.RandomRotation(0.1)(x)\n",
    "\n",
    "x = base_model(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(700, activation='relu')(x)\n",
    "x = Dropout(0.35)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(350, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Dense(150, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(75, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "outputs = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 299, 299, 3)       0         \n",
      "                                                                 \n",
      " random_rotation (RandomRota  (None, 299, 299, 3)      0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 700)               91751100  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 700)               0         \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 700)              2800      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 350)               245350    \n",
      "                                                                 \n",
      " batch_normalization_95 (Bat  (None, 350)              1400      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 350)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 75)                26325     \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 75)               300       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,830,591\n",
      "Trainable params: 92,025,557\n",
      "Non-trainable params: 21,805,034\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Format the date and time\n",
    "formatted_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                       factor=0.1,\n",
    "                       patience=2,\n",
    "                       verbose=1,\n",
    "                       min_lr=0)\n",
    "\n",
    "mcp = ModelCheckpoint(\"{}_Inception_V3.keras\".format(formatted_time),\n",
    "                      monitor='val_loss',\n",
    "                      mode='auto',\n",
    "                      verbose=0,\n",
    "                      save_best_only=True)\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy', \n",
    "                   mode = 'max', \n",
    "                   patience = 3, \n",
    "                   verbose = 1, \n",
    "                   restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0001\n",
    "# lr_schedule = ExponentialDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=10,\n",
    "#     decay_rate=0.99,\n",
    "#     staircase=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "classes = np.array([label for _, label in train_ds.unbatch()])\n",
    "integer_classes = np.argmax(classes, axis=1)\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(integer_classes), y=integer_classes)\n",
    "weights_dict = {i: weight for i, weight in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "495/718 [===================>..........] - ETA: 48:43 - loss: 2.0346 - accuracy: 0.2670"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = model.fit(preproc_train_ds, \n",
    "                    validation_data=preproc_val_ds, \n",
    "                    epochs=100,\n",
    "                    class_weight=weights_dict,\n",
    "                    callbacks=[es, mcp, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T15:44:54.948152Z",
     "iopub.status.busy": "2024-05-09T15:44:54.947389Z",
     "iopub.status.idle": "2024-05-09T15:45:31.324902Z",
     "shell.execute_reply": "2024-05-09T15:45:31.324018Z",
     "shell.execute_reply.started": "2024-05-09T15:44:54.948119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 161ms/step - accuracy: 0.4818 - loss: 1.3598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2761727571487427, 0.5256338715553284]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(preproc_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T15:46:28.066318Z",
     "iopub.status.busy": "2024-05-09T15:46:28.065902Z",
     "iopub.status.idle": "2024-05-09T15:46:36.793514Z",
     "shell.execute_reply": "2024-05-09T15:46:36.792598Z",
     "shell.execute_reply.started": "2024-05-09T15:46:28.066284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 files belonging to 7 classes.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 379ms/step - accuracy: 0.5625 - loss: 1.2150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2297910451889038, 0.5471428632736206]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_ds = image_dataset_from_directory(\n",
    "    directory='/kaggle/input/balanced-test/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(299, 299),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "preproc_balanced_test_ds = balanced_test_ds.map(preprocess_data)\n",
    "model.evaluate(preproc_balanced_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.295762Z",
     "iopub.status.idle": "2024-05-09T13:41:27.296669Z",
     "shell.execute_reply": "2024-05-09T13:41:27.296451Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.296431Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('Inception_v3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.297960Z",
     "iopub.status.idle": "2024-05-09T13:41:27.298361Z",
     "shell.execute_reply": "2024-05-09T13:41:27.298145Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.298132Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.300152Z",
     "iopub.status.idle": "2024-05-09T13:41:27.300638Z",
     "shell.execute_reply": "2024-05-09T13:41:27.300462Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.300445Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.302856Z",
     "iopub.status.idle": "2024-05-09T13:41:27.303420Z",
     "shell.execute_reply": "2024-05-09T13:41:27.303109Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.303090Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model('/kaggle/input/inception_v3_2/tensorflow2/inception_v3/1/Inception_v3.keras')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.305109Z",
     "iopub.status.idle": "2024-05-09T13:41:27.305649Z",
     "shell.execute_reply": "2024-05-09T13:41:27.305397Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.305375Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model.evaluate(preproc_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.307582Z",
     "iopub.status.idle": "2024-05-09T13:41:27.307945Z",
     "shell.execute_reply": "2024-05-09T13:41:27.307797Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.307784Z"
    }
   },
   "outputs": [],
   "source": [
    "balanced_test_ds = image_dataset_from_directory(\n",
    "    directory='/kaggle/input/balanced-test/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(299, 299),\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.309211Z",
     "iopub.status.idle": "2024-05-09T13:41:27.309558Z",
     "shell.execute_reply": "2024-05-09T13:41:27.309414Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.309400Z"
    }
   },
   "outputs": [],
   "source": [
    "preproc_balanced_test_ds = balanced_test_ds.map(preprocess_data)\n",
    "loaded_model.evaluate(preproc_balanced_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.311212Z",
     "iopub.status.idle": "2024-05-09T13:41:27.311893Z",
     "shell.execute_reply": "2024-05-09T13:41:27.311464Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.311446Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(preproc_balanced_test_ds)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Retrieve true labels\n",
    "true_labels = np.concatenate([y for x, y in preproc_balanced_test_ds], axis=0)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels.argmax(axis=1), predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.313063Z",
     "iopub.status.idle": "2024-05-09T13:41:27.313465Z",
     "shell.execute_reply": "2024-05-09T13:41:27.313313Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.313298Z"
    }
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.315339Z",
     "iopub.status.idle": "2024-05-09T13:41:27.315810Z",
     "shell.execute_reply": "2024-05-09T13:41:27.315534Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.315521Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for images, label_batch in train_ds:\n",
    "    labels.extend(label_batch.numpy())  # Ensure labels are numpy arrays, not tensors\n",
    "\n",
    "labels = np.array(labels)  # Convert list of labels to a numpy array\n",
    "\n",
    "# Compute class weights\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels.flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.316828Z",
     "iopub.status.idle": "2024-05-09T13:41:27.317146Z",
     "shell.execute_reply": "2024-05-09T13:41:27.317000Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.316987Z"
    }
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in val_ds:\n",
    "  integer_labels = np.argmax(labels_batch, axis=1)\n",
    "  print(integer_labels)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-09T13:41:27.318901Z",
     "iopub.status.idle": "2024-05-09T13:41:27.319259Z",
     "shell.execute_reply": "2024-05-09T13:41:27.319088Z",
     "shell.execute_reply.started": "2024-05-09T13:41:27.319074Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "\n",
    "# def upload_file_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
    "#     \"\"\"Uploads a file to the Google Cloud Storage bucket.\"\"\"\n",
    "#     # Set up the client with Google Cloud credentials\n",
    "#     storage_client = storage.Client.from_service_account_json('path/to/your/service-account-key.json')\n",
    "    \n",
    "#     # Get the bucket\n",
    "#     bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "#     # Create a blob object from the filepath\n",
    "#     blob = bucket.blob(destination_blob_name)\n",
    "    \n",
    "#     # Upload the file to a destination\n",
    "#     blob.upload_from_filename(source_file_name)\n",
    "\n",
    "#     print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n",
    "\n",
    "# # Example usage\n",
    "# upload_file_to_gcs('hayd1621', 'local/path/to/your/file', 'dest"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1028436,
     "sourceId": 1732825,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4967018,
     "sourceId": 8358300,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 38287,
     "sourceId": 45667,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
